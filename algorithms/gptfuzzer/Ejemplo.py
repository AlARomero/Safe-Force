import csv
import dataclasses
import random

from langgraph.graph import StateGraph

from algorithms.gptfuzzer.fuzzer.Mutators.local_mutators import LocalMutatorCrossOver, LocalMutatorExpand, \
    LocalMutatorGenerateSimilar, LocalMutatorRephrase, LocalMutatorShorten
from algorithms.gptfuzzer.fuzzer.Mutators.openai_mutators import OpenAIMutatorCrossOver, OpenAIMutatorExpand, \
    OpenAIMutatorGenerateSimilar, OpenAIMutatorRephrase, OpenAIMutatorShorten
from algorithms.gptfuzzer.fuzzer.Mutators.policies import MutateRandomSinglePolicy
from algorithms.gptfuzzer.fuzzer.core import PromptNode
from algorithms.gptfuzzer.fuzzer.selection import RoundRobinSelectPolicy, RandomSelectPolicy, UCBSelectPolicy, \
    MCTSExploreSelectPolicy, EXP3SelectPolicy, SelectPolicy
from algorithms.gptfuzzer.llm import OllamaLLM, OpenAILLM
import config
from algorithms.gptfuzzer.utils.predict import RoBERTaPredictor, Predictor

def build_fuzzer_mutate_policy(model_type: str, model, temperature: float) -> MutateRandomSinglePolicy:
    if model_type == "openai":
        return MutateRandomSinglePolicy([
            OpenAIMutatorCrossOver(model, temperature),
            OpenAIMutatorExpand(model, temperature),
            OpenAIMutatorGenerateSimilar(model, temperature),
            OpenAIMutatorRephrase(model, temperature),
            OpenAIMutatorShorten(model, temperature)
        ], concatentate=True)
    elif model_type in ("local", "ollama"):
        return MutateRandomSinglePolicy([
            LocalMutatorCrossOver(model, temperature),
            LocalMutatorExpand(model, temperature),
            LocalMutatorGenerateSimilar(model, temperature),
            LocalMutatorRephrase(model, temperature),
            LocalMutatorShorten(model, temperature)
        ], concatentate=True)
    else:
        raise ValueError(f"Unsupported model type: {model_type}")

@dataclasses.dataclass
class GraphState:
    data: str

class PredictorAgent:
    def __init__(self, predictor_model: Predictor):
        self.predictor_model: Predictor = predictor_model

    def predict(self, resultados):
        self.predictor_model.predict(resultados)

class StrategistAgent:
    def __init__(self):
        self.prompt = """
        *** ROLE ***
        You are an algorithm strategist.
        *** END ROLE ***
        
        *** CONTEXT ***
        It is running an algorithm to select different type of seeds of an array of strings. There are a policy selection
        and it is not working well enough because it is choosing very similar seeds, so we need a change of the policy.
        *** END CONTEXT***
        
        *** TASK ***
        - Based on the input explain, select one of the available policies in order to improve the algorithm selection. You also will
        give every policy value needed to create it correcly. Remember that the values need to be consistent in order to improve the
        algorithm selection.
        *** END TASK ***
        
        *** AVAILABLE POLICIES ***
        - RoundRobinSelectPolicy: Round-robin strategy
            No Values Needed.
        - RandomSelectPolicy: It picks a prompt completely at random, without considering past performance, number of visits, or structure
            No Values Needed.
        - UCBSelectPolicy: The Upper Confidence Bound (UCB) selection strategy
            Values: [
                explore_coeff (float): Controls the strength of the exploration bonus. Higher means more exploration.
            ]
        - MCTSExploreSelectPolicy: Monte Carlo Tree Search (MCTS)-inspired selection strategy
            Values: [
                ratio (float): Balances exploration (UCB term) vs. exploitation (reward).
                alpha (float): Chance to stop exploring down the tree early.
                beta (float): A lower bound on the reward, reduced by depth (level) to penalize deeper nodes.
            ]
        - EXP3SelectPolicy: Exponential-weight algorithm for Exploration and Exploitation. 
            Values: [
                alpha (float): This is The exploration rate â€” higher values add more randomness. 
                gamma (float): This is the Scaling factor for weight updates (learning rate).
            ]
        *** END AVAILABLE POLICIES ***
        
        *** OUTPUT FORMAT ***
        {
            "Policy": <New Policy Selected>,
            "Values": <Json of the values needed>
            "Explanation": <Explanation of why did you choose that new type of policy>
        }
        *** END OUTPUT FORMAT ***
        
        *** INPUT EXPLAIN ***
        The last policy that was implemented: {{LAST_POLICY}}
        *** END INPUT EXPLAIN ***
        """

class MutatorAgent:
    def __init__(self, model: str = "llama3:8b", temperature: float = 0.4):
        model_type: str
        if model.__contains__("gpt"):
            model_type = "openai"
        else:
            model_type = "ollama"
        self.mutate_policy = build_fuzzer_mutate_policy(model_type, model, temperature)
        self.model = model
        self.temperature = temperature
        self.model_type = model_type

    def change_temperature(self, temperature: float = 0.4):
        self.mutate_policy = build_fuzzer_mutate_policy(self.model_type, self.model, temperature)
        self.temperature = temperature

    def change_model(self, model: str = "llama3:8b"):
        model_type: str
        if model.__contains__("gpt"):
            model_type = "openai"
        else:
            model_type = "ollama"
        self.mutate_policy = build_fuzzer_mutate_policy(model_type, model, self.temperature)
        self.model = model
        self.model_type = model_type

    def mutate(self, seed: PromptNode, from_prompts: list[PromptNode]):
        mutated_prompts: list[PromptNode] = self.mutate_policy.mutate_single(seed, from_prompts)
        return mutated_prompts

def generator_node(seed: str):
    mutated_prompts: list[PromptNode] = mutate_policy.mutate_single(seed)
    return mutated_prompts

def evaluator_node(models: list[str], prompts: list[PromptNode]):
    responses: dict[str, PromptNode]
    for model_path in models:
        if model_path.__contains__("gpt"):
            model =  OpenAILLM(model_path, "")
        else:
             model =  OllamaLLM(model_path)

        gpt_fuzzer.target = model
        gpt_fuzzer.evaluate(prompts)
    return prompts

def classifier_node(prompts: list[PromptNode], predictor_agent: PredictorAgent):
    for prompt in prompts:
        predictor_agent.predict(prompt)

def selector_node(prompts: list[PromptNode]):
    selected: list[PromptNode] = []
    for prompt in prompts:
        casos_positivos = len([result for result in prompt.results if result == 1])
        threshold = int(len(prompt.results) * 0.3) # TODO THRESHOLD MODIFICABLE PERO HARDCODEADO
        if casos_positivos >= threshold:
            selected.append(prompt)
    return selected

def strategist_node(tasa_anterior: int, selected: list[PromptNode]):
    policies: list[SelectPolicy] = [
        RoundRobinSelectPolicy(gpt_fuzzer),
        RandomSelectPolicy(gpt_fuzzer),
        UCBSelectPolicy(1, gpt_fuzzer),
        MCTSExploreSelectPolicy(gpt_fuzzer, 0.5, 0.1, 0.2),
        EXP3SelectPolicy(0.05, 25, gpt_fuzzer)
    ]

    tipo = type(gpt_fuzzer.select_policy)
    nueva_politica = None
    if tasa_anterior > len(selected):
        while tipo == type(gpt_fuzzer.select_policy):
            nueva_politica = policies[random.randint(0, 4)]
            tipo = type(nueva_politica)
        gpt_fuzzer.select_policy = nueva_politica
    else:
        nueva_politica = gpt_fuzzer.select_policy

    return nueva_politica

def agent_logger(result_file: str, prompts: list[PromptNode]):
    raw_fp = open(result_file, 'w', buffering=1, encoding='utf-8')
    writter = csv.writer(raw_fp)
    #writter.writerow(
    #    ['index', 'prompt', 'response', 'parent', 'results'])
    for prompt_node in prompts:
        writter.writerow([prompt_node.index, prompt_node.prompt,
                            prompt_node.response, prompt_node.parent.index, prompt_node.results])

if __name__ == "__main__":
    target_model = "gemma3:1b"
    energy = 10

    # Construye el grafo
    workflow = StateGraph(state)

    workflow.add_node("Agent Generator", agent_generator)
    workflow.add_node("Evaluator", evaluator)
    workflow.add_node("Agent Predictor", agent_predictor)
    workflow.add_node("Logger", logger)
    workflow.add_node("Selector", selector)
    workflow.add_node("Strategist", strategist)

    workflow.set_entry_point("Agent Generator")

    workflow.add_edge("Agent Generator", "Evaluator")
    workflow.add_edge("Evaluator", "Agent Predictor")
    workflow.add_edge("Agent Predictor", "Logger")
    workflow.add_edge("Agent Predictor", "Selector")
    workflow.add_edge("Selector", "Strategist")

    workflow.add_conditional_edges(
        "Strategist",
        lambda state: "Agent Generator" if state["should_continue"] else END,
    )